{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "from classification.utils.plots import (\n",
    "    plot_decision_boundaries,\n",
    "    plot_specgram,\n",
    "    show_confusion_matrix,\n",
    "    confusion_matrix\n",
    ")\n",
    "from classification.utils.utils import accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "fm_dir = \"data/feature_matrices/\"\n",
    "model_dir = \"data/models/\"\n",
    "\n",
    "nclass = dataset.nclass\n",
    "naudio = dataset.naudio\n",
    "classnames = dataset.list_classes()\n",
    "num_classes = len(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    print(\"Iteration: \", i)\n",
    "\n",
    "    np.random.seed(int(time.time()))\n",
    "\n",
    "    print(\"seed = \", int(time.time()))\n",
    "    \n",
    "    # 'echo', 'time_shift', 'scaling', 'pitch_shift', \n",
    "\n",
    "    myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, shift_pct=1.5, data_aug=['time_shift'])\n",
    "\n",
    "    feature_length = len(myds[classnames[0], 0])\n",
    "    data_aug_factor = myds.data_aug_factor\n",
    "\n",
    "\n",
    "    X_aug = np.zeros((data_aug_factor * nclass * naudio, 20, 20, 1))\n",
    "    y_aug = np.zeros(data_aug_factor * nclass * naudio)\n",
    "\n",
    "    for s in range(data_aug_factor):\n",
    "        for idx in range(dataset.naudio):\n",
    "            for class_idx, classname in enumerate(classnames):\n",
    "                y_aug[s* nclass * naudio + class_idx * naudio + idx] = class_idx\n",
    "                featvec = myds[classname, idx]\n",
    "                X_aug[ s* nclass * naudio + class_idx * naudio + idx, :, :] = featvec.reshape(20, 20, 1)\n",
    "\n",
    "    np.save(fm_dir + \"feature_matrix_2D_aug.npy\", X_aug)\n",
    "    np.save(fm_dir + \"labels_aug.npy\", y_aug)\n",
    "\n",
    "    X_aug = np.load(fm_dir + \"feature_matrix_2D_aug.npy\")\n",
    "    y_aug = np.load(fm_dir + \"labels_aug.npy\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_aug, y_aug, test_size=0.9, stratify=y_aug\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(20, 20, 1)),\n",
    "        layers.Normalization(),\n",
    "        layers.Conv2D(128, kernel_size=(4, 4), activation='leaky_relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(256, kernel_size=(4, 4), activation='leaky_relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='leaky_relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adamw',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \"\"\"\n",
    "    model = models.load_model(model_dir + \"two.keras\")\n",
    "    \n",
    "    ### change learining rate\n",
    "    learning_rate = 0.1 * 10**(-np.log(i+1))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    # history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), shuffle=True)\n",
    "\n",
    "    # store the model\n",
    "\n",
    "    model.save(model_dir + \"two.keras\", zipped=True)\n",
    "\n",
    "    # evaluate the model\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(f'Test loss: {test_loss}')\n",
    "\n",
    "    # plot the confusion matrix\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(3, 3))\n",
    "    confmat = confusion_matrix(y_test, y_pred_classes)\n",
    "    sns.heatmap(confmat.T, square=True, annot=True, fmt=\"d\", cbar=False, xticklabels=classnames, yticklabels=classnames)\n",
    "    plt.xlabel(\"True label\", fontsize=8)\n",
    "    plt.ylabel(\"Predicted label\", fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/confusion_matrix.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "     #calculate the f1 score\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "    # calculate the percentage for each class\n",
    "    class_percentages = np.mean(y_pred, axis=0) * 100\n",
    "    for classname, percentage in zip(classnames, class_percentages):\n",
    "        print(f'{classname}: {percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### play all the sounds\n",
    "audio_util = AudioUtil()\n",
    "\n",
    "for classname in classnames:\n",
    "    for idx in range(40):\n",
    "        path = dataset.__getitem__((classname, idx))\n",
    "        audio = audio_util.open(path)\n",
    "        audio_util.play(audio)\n",
    "        time.sleep(5)\n",
    "        print(f'Playing {classname} {idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the prediction file\n",
    "\n",
    "data = pd.read_csv('C:\\LELEC210X\\LELEC210X\\predictions.csv')\n",
    "\n",
    "# plot the confusion matrix\n",
    "\n",
    "y_pred = data['prediction']\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i] = [float(x) for x in y_pred[i].replace('[', '').replace(']', '').split()]\n",
    "    y_pred[i] = classnames[np.argmax(y_pred[i])]\n",
    "y_test = np.repeat(classnames, 134)\n",
    "y_pred_mean = data['mean_prediction']\n",
    "for i in range(len(y_pred_mean)):\n",
    "    y_pred_mean[i] = [float(x) for x in y_pred_mean[i].replace('[', '').replace(']', '').split()]\n",
    "    y_pred_mean[i] = classnames[np.argmax(y_pred_mean[i])]\n",
    "y_pred_weighted = data['weighted_prediction']\n",
    "for i in range(len(y_pred_weighted)):\n",
    "    y_pred_weighted[i] = [float(x) for x in y_pred_weighted[i].replace('[', '').replace(']', '').split()]\n",
    "    y_pred_weighted[i] = classnames[np.argmax(y_pred_weighted[i])]\n",
    "    \n",
    "sns.set(font_scale=0.8)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "confmat = confusion_matrix(y_test, y_pred[:-1])\n",
    "sns.heatmap(confmat.T, square=True, annot=True, fmt=\"d\", cbar=False, xticklabels=classnames, yticklabels=classnames)\n",
    "plt.xlabel(\"True label\", fontsize=8)\n",
    "plt.ylabel(\"Predicted label\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/confusion_matrix_direct_predictions.pdf\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "confmat = confusion_matrix(y_test, y_pred_mean[:-1])\n",
    "sns.heatmap(confmat.T, square=True, annot=True, fmt=\"d\", cbar=False, xticklabels=classnames, yticklabels=classnames)\n",
    "plt.xlabel(\"True label\", fontsize=8)\n",
    "plt.ylabel(\"Predicted label\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/confusion_matrix_mean_predictions.pdf\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "confmat = confusion_matrix(y_test, y_pred_weighted[:-1])\n",
    "sns.heatmap(confmat.T, square=True, annot=True, fmt=\"d\", cbar=False, xticklabels=classnames, yticklabels=classnames)\n",
    "plt.xlabel(\"True label\", fontsize=8)\n",
    "plt.ylabel(\"Predicted label\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/confusion_matrix_weighted_predictions.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# print the accuracy\n",
    "\n",
    "print(f'Accuracy for the direct predictions: {accuracy(y_pred[:-1], y_test)}')\n",
    "print(f'Accuracy for the mean predictions: {accuracy(y_pred_mean[:-1], y_test)}')\n",
    "print(f'Accuracy for the weighted predictions: {accuracy(y_pred_weighted[:-1], y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the prediction file\n",
    "\n",
    "data_new = pd.read_csv('C:\\LELEC210X\\LELEC210X\\predictions_three_keras.csv')\n",
    "\n",
    "# plot the confusion matrix\n",
    "\n",
    "y_pred = data_new['prediction']\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i] = [float(x) for x in y_pred[i].replace('[', '').replace(']', '').split()]\n",
    "    y_pred[i] = classnames[np.argmax(y_pred[i])]\n",
    "y_test = np.repeat(classnames, 658/5)\n",
    "y_pred_mean = data_new['mean_prediction']\n",
    "for i in range(len(y_pred_mean)):\n",
    "    y_pred_mean[i] = [float(x) for x in y_pred_mean[i].replace('[', '').replace(']', '').split()]\n",
    "    y_pred_mean[i] = classnames[np.argmax(y_pred_mean[i])]\n",
    "y_pred_weighted = data_new['weighted_prediction']\n",
    "for i in range(len(y_pred_weighted)):\n",
    "    y_pred_weighted[i] = [float(x) for x in y_pred_weighted[i].replace('[', '').replace(']', '').split()]\n",
    "    y_pred_weighted[i] = classnames[np.argmax(y_pred_weighted[i])]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "confmat = confusion_matrix(y_test, y_pred[:-4])\n",
    "sns.heatmap(confmat.T, square=True, annot=True, fmt=\"d\", cbar=False, xticklabels=classnames, yticklabels=classnames)\n",
    "plt.xlabel(\"True label\", fontsize=8)\n",
    "plt.ylabel(\"Predicted label\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/confusion_matrix_prev_predictions.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# print the accuracy\n",
    "\n",
    "print(f'Accuracy for the predictions: {accuracy(y_pred[:-4], y_test)}')\n",
    "print(f'Accuracy for the mean predictions: {accuracy(y_pred_mean[:-4], y_test)}')\n",
    "print(f'Accuracy for the weighted predictions: {accuracy(y_pred_weighted[:-4], y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
