{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "import scipy.signal as signal\n",
    "\n",
    "import time\n",
    "\n",
    "# tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_signal = 10200\n",
    "\n",
    "curDir = str(os.getcwd())\n",
    "\n",
    "seed = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esc50_csv = curDir+ r'\\src\\classification\\datasets\\ESC-50\\meta\\esc50.csv'\n",
    "base_data_path = curDir+ r'\\src\\classification\\datasets\\ESC-50\\audio'\n",
    "\n",
    "pd_data = pd.read_csv(esc50_csv)\n",
    "\n",
    "my_classes = ['chainsaw', 'helicopter', 'fireworks', 'gun']\n",
    "map_class_to_id  = {label: idx for idx, label in enumerate(my_classes)}\n",
    "\n",
    "filtered_pd = pd_data[pd_data.category.isin(my_classes)]\n",
    "\n",
    "class_id = filtered_pd['category'].apply(lambda name: map_class_to_id[name])\n",
    "filtered_pd = filtered_pd.assign(target=class_id)\n",
    "\n",
    "\"\"\"\n",
    "unknown_pd = pd_data[~pd_data.category.isin(my_classes)]\n",
    "\n",
    "unknown_pd = unknown_pd.assign(target=5)\n",
    "\n",
    "# reduce the number of unknown samples to balance the dataset\n",
    "\n",
    "unknown_pd = unknown_pd.sample(frac=40/1800, random_state=int(time.time()))\n",
    "\n",
    "filtered_pd = pd.concat([filtered_pd, unknown_pd])\n",
    "\"\"\"\n",
    "\n",
    "full_path = filtered_pd['filename'].apply(lambda row: os.path.join(base_data_path, row))\n",
    "filtered_pd = filtered_pd.assign(filename=full_path)\n",
    "\n",
    "filenames = filtered_pd['filename']\n",
    "targets = filtered_pd['target']\n",
    "folds = filtered_pd['fold']\n",
    "\n",
    "main_ds = tf.data.Dataset.from_tensor_slices((filenames, targets, folds))\n",
    "\n",
    "\"\"\"\n",
    "IR_path = curDir + '\\classification\\src\\classification\\datasets\\ESC-50\\IR'\n",
    "\n",
    "IR_files = os.listdir(IR_path)\n",
    "IR_files = [os.path.join(IR_path, file) for file in IR_files]\n",
    "\n",
    "IR_files = tf.convert_to_tensor(IR_files)\n",
    "\n",
    "IR_ds = tf.data.Dataset.from_tensor_slices(IR_files)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_wav_16k_mono(filename):\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=10200)\n",
    "    return wav\n",
    "\n",
    "@tf.function\n",
    "def load_wav_for_map(filename, label, fold):\n",
    "  return load_wav_16k_mono(filename), label, fold\n",
    "\n",
    "def convolve(x, y):\n",
    "  return signal.convolve(x, y, mode='same').astype(np.float32)\n",
    "\"\"\"\n",
    "@tf.function\n",
    "def apply_IR(wav, label, fold):\n",
    "  IR = IR_ds.shuffle(buffer_size=1000).take(1)\n",
    "  IR = next(iter(IR))\n",
    "  wav = tf.numpy_function(convolve, [wav, IR], tf.float32)\n",
    "  return wav, label, fold\n",
    "\"\"\"\n",
    "@tf.function\n",
    "def apply_time_shift(wav, label, fold):\n",
    "  if len(wav) < 20*512:\n",
    "    sig = tf.zeros(20*512, dtype=tf.float32)\n",
    "    shift = tf.random.uniform(shape=[], minval=0, maxval=20*512 - len(wav), dtype=tf.int32)\n",
    "    sig = tf.concat([sig[:shift], wav, sig[shift+len(wav):]], 0)\n",
    "    return sig, label, fold\n",
    "  else:\n",
    "    shift = tf.random.uniform(shape=[], minval=0, maxval=tf.shape(wav)[0] - 20*512, dtype=tf.int32)\n",
    "    wav = wav[shift:shift+20*512]\n",
    "    return wav, label, fold\n",
    "\n",
    "@tf.function\n",
    "def apply_bandpass(wav, label, fold):\n",
    "  filter = signal.butter(10, [500, 5000], btype='bandpass', fs=10200, output='sos')\n",
    "  wav = tf.numpy_function(lambda x: signal.sosfilt(filter, x).astype(np.float32), [wav], tf.float32)\n",
    "  return wav, label, fold\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def apply_echo(wav, label, fold):\n",
    "  shift = tf.random.uniform(shape=[], minval=0, maxval=1024, dtype=tf.int32)\n",
    "  echo = tf.roll(wav, shift=shift, axis=0)\n",
    "  amplitude = tf.random.uniform(shape=[], minval=0.05, maxval=0.1, dtype=tf.float32)\n",
    "  echo = echo * amplitude\n",
    "  return wav + echo, label, fold\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def apply_noise(wav, label, fold):\n",
    "  # get wav energy\n",
    "  energy = tf.reduce_sum(wav ** 2) / tf.cast(tf.size(wav), tf.float32)\n",
    "  # add gaussian noise\n",
    "  noise = tf.random.normal(tf.shape(wav), mean = 0.0, stddev = energy, dtype=tf.float32)\n",
    "  return wav + noise, label, fold\n",
    "\n",
    "@tf.function\n",
    "def wav2spec(wav, label, fold):\n",
    "  spectrogram = tfio.audio.spectrogram(wav, nfft=512, window=256, stride=512)\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  mel_spectrogram = tfio.audio.melscale(spectrogram, rate=12000, mels=20, fmin=0, fmax=6000)\n",
    "  mel_spectrogram = tf.expand_dims(mel_spectrogram, -1)  # Ensure 3 dimensions\n",
    "  mel_spectrogram = tf.image.rot90(mel_spectrogram, k=-1)\n",
    "  return mel_spectrogram, label, fold\n",
    "\n",
    "@tf.function\n",
    "def float_to_quint16(spec, label, fold):\n",
    "  return tf.cast(spec, tf.uint16), label, fold\n",
    "\n",
    "@tf.function\n",
    "def is_validation(fold):\n",
    "  return fold == 1\n",
    "\n",
    "@tf.function\n",
    "def is_test(fold):\n",
    "  return fold == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IR_ds = IR_ds.map(load_wav_16k_mono)\n",
    "\n",
    "main_ds = main_ds.map(load_wav_for_map)\n",
    "\n",
    "# apply impulse response to the audio data\n",
    "# main_ds_IR = main_ds.map(apply_IR)\n",
    "# main_ds = main_ds.concatenate(main_ds_IR)\n",
    "\n",
    "# apply time shift to the audio data\n",
    "main_ds_time_shift_1 = main_ds.map(apply_time_shift)\n",
    "main_ds_time_shift_2 = main_ds.map(apply_time_shift)\n",
    "main_ds_time_shift_3 = main_ds.map(apply_time_shift)\n",
    "main_ds_time_shift_4 = main_ds.map(apply_time_shift)\n",
    "main_ds = main_ds_time_shift_1\n",
    "main_ds = main_ds.concatenate(main_ds_time_shift_2)\n",
    "main_ds = main_ds.concatenate(main_ds_time_shift_3)\n",
    "main_ds = main_ds.concatenate(main_ds_time_shift_4)\n",
    "\n",
    "# main_ds_bandpass = main_ds.map(apply_bandpass)\n",
    "# main_ds = main_ds.concatenate(main_ds_bandpass)\n",
    "\n",
    "#main_ds_echo = main_ds.map(apply_echo)\n",
    "#main_ds = main_ds.concatenate(main_ds_echo)\n",
    "\n",
    "\"\"\"\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i, (wav, label, fold) in enumerate(main_ds.take(9)):\n",
    "  r, c = i // 3, i % 3\n",
    "  ax = axes[r, c]\n",
    "  ax.plot(wav.numpy())\n",
    "  ax.set_title(my_classes[label.numpy()])\n",
    "  ax.axis('off')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "main_ds_noise = main_ds.map(apply_noise)\n",
    "main_ds = main_ds.concatenate(main_ds_noise)\n",
    "\n",
    "\"\"\"\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i, (wav, label, fold) in enumerate(main_ds.take(9)):\n",
    "  r, c = i // 3, i % 3\n",
    "  ax = axes[r, c]\n",
    "  ax.plot(wav.numpy())\n",
    "  ax.set_title(my_classes[label.numpy()])\n",
    "  ax.axis('off')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# apply a melspectrogram transformation to the audio data\n",
    "main_ds = main_ds.map(wav2spec)\n",
    "\n",
    "# main_ds = main_ds.map(float_to_quint16)\n",
    "\n",
    "gun_ds = main_ds.filter(lambda spec, label, fold: label == 2)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i, (spec, label, fold) in enumerate(gun_ds.take(9)):\n",
    "  r, c = i // 3, i % 3\n",
    "  ax = axes[r, c]\n",
    "  ax.imshow(spec.numpy(), cmap='inferno')\n",
    "  ax.set_title(my_classes[label.numpy()])\n",
    "  ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "spec, label, fold = next(iter(main_ds.take(1)))\n",
    "plt.imshow(spec.numpy(), cmap='inferno')\n",
    "plt.title(my_classes[label.numpy()])\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for i, (spec, label, fold) in enumerate(main_ds.take(16)):\n",
    "  r, c = i // 4, i % 4\n",
    "  ax = axes[r, c]\n",
    "  ax.imshow(spec.numpy(), cmap='inferno')\n",
    "  ax.set_title(my_classes[label.numpy()])\n",
    "  ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "file1 = np.load(\"classification/data/melspecs/0005001a00.npy\")\n",
    "plt.imshow(file1.reshape(20, 20), cmap='inferno')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# split the dataset into training and validation sets\n",
    "\n",
    "train_ds = main_ds.filter(lambda wav, label, fold: not is_validation(fold) and not is_test(fold))\n",
    "val_ds = main_ds.filter(lambda wav, label, fold: is_validation(fold))\n",
    "test_ds = main_ds.filter(lambda wav, label, fold: is_test(fold))\n",
    "\n",
    "# shuffle the training dataset\n",
    "\n",
    "train_ds = train_ds.shuffle(buffer_size=1000, reshuffle_each_iteration=True, seed = seed)\n",
    "\n",
    "# batch the datasets\n",
    "\n",
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)\n",
    "test_ds = test_ds.batch(32)\n",
    "\n",
    "# prepare the datasets for training\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build the model\n",
    "\n",
    "@tf.function\n",
    "def normalize(x):\n",
    "  return x / tf.reduce_max(x)\n",
    "\n",
    "def build_model(input_shape):\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "  model.add(tf.keras.layers.Lambda(normalize))\n",
    "  model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "  model.add(tf.keras.layers.Dropout(0.2))\n",
    "  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.3))\n",
    "  model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "  return model\n",
    "\n",
    "input_shape = (20, 20, 1)\n",
    "\n",
    "model_path = curDir + r'\\data\\models\\four.keras'\n",
    "\n",
    "new_model = False\n",
    "\n",
    "if not new_model:\n",
    "  model = tf.keras.models.load_model(model_path, custom_objects={'normalize': normalize})\n",
    "else:\n",
    "  model = build_model(input_shape)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=['accuracy'],\n",
    "        weighted_metrics=[])\n",
    "        \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=1, verbose=2)\n",
    "\n",
    "model.save(model_path)\n",
    "\n",
    "# evaluate the model\n",
    "\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "# plot the confusion matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for x, y, _ in test_ds:\n",
    "  y_true.extend(y)\n",
    "  y_pred.extend(model.predict(x).argmax(axis=1))\n",
    "  \n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# plot the training history\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 5))\n",
    "\n",
    "# Plot the training history\n",
    "ax[0].plot(history.history['accuracy'], label='accuracy')\n",
    "ax[0].plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(loc='lower right')\n",
    "ax[0].set_title('Training and Validation Accuracy')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "heatmap(cm, annot=True, xticklabels=my_classes, yticklabels=my_classes, ax=ax[1])\n",
    "ax[1].set_xlabel('Predicted')\n",
    "ax[1].set_ylabel('True')\n",
    "ax[1].set_title('Confusion Matrix, accuracy = {:.2f}'.format(accuracy))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fm_dir = \"classification/data/feature_matrices/\"\n",
    "\n",
    "file1 = np.load(fm_dir + \"../melspecs/0005001a00.npy\")\n",
    "file2 = np.load(fm_dir + \"../melspecs/0002001900.npy\")\n",
    "file3 = np.load(fm_dir + \"../melspecs/0004001500.npy\")\n",
    "file4 = np.load(fm_dir + \"../melspecs/0004001900.npy\")\n",
    "file5 = np.load(fm_dir + \"../melspecs/0005000700.npy\")\n",
    "file6 = np.load(fm_dir + \"../melspecs/0005001200.npy\")\n",
    "file7 = np.load(fm_dir + \"../melspecs/0005002200.npy\")\n",
    "file8 = np.load(fm_dir + \"../melspecs/0017002200.npy\")\n",
    "file9 = np.load(fm_dir + \"../melspecs/0026000000.npy\")\n",
    "\n",
    "y_aug = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "X_aug = [file1.reshape(20,20,1), file2.reshape(20,20,1), file3.reshape(20,20,1), file4.reshape(20,20,1), file5.reshape(20,20,1), file6.reshape(20,20,1), file7.reshape(20,20,1), file8.reshape(20,20,1), file9.reshape(20,20,1)]\n",
    "\n",
    "X_aug = tf.constant(X_aug)\n",
    "\n",
    "# Ensure the input has the correct dimensions\n",
    "\n",
    "y_pred = model.predict(X_aug).argmax(axis=1)\n",
    "print (y_pred) \n",
    "\n",
    "# Plot the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_aug, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "\n",
    "heatmap(cm, annot=True, xticklabels=my_classes, yticklabels=my_classes, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
